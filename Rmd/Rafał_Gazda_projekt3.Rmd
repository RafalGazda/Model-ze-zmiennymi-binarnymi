---
title: "Cwiczenia 3"
author: "RafaĹ‚ Gazda"
date: "15 grudnia 2018"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r warning=FALSE, message=FALSE}
library(caTools)
library(lmtest)
library(randtests)
library(strucchange)
library(car)
library(tidyr)
library(dplyr)

```
## Zad 1

Po wgraniu danych, które zawierają 100 obserwacji zostaną one podzielone na dwie częśći _train_ oraz _test_. Za pomocą częśći _train_ zbudujemy model ekonometryczny, a za pomocą próbki _test_ zostanie on przetestowany.

```{r}
MyData <- read.csv('C:/Users/Gazi/Desktop/Projekt3/DaneZ3.csv', header=TRUE, sep=";", dec=',')
set.seed(284095)

sample = sample(1:100, 10, replace=FALSE)
train = MyData[-sample,] 
test = MyData[sample,]
```

## Zad 2
W projekcie zostanie dobrana odpowiednia postać modelu ekonometrycznego. Podczas budowy modelu trzeba zwórcić uwagę na zmienną _Z7_, która nie jest zmienną numeryczną, dlatego też zostanie ona zmieniona na zmienne zero-jedynkowe.

```{r}
modelMNK <- lm(train)
summary(modelMNK)
```
W tej części projektu zostanie sprawdzone, czy postać liniowa jest optymalna. Posłuż do tego testem _serii Walda-Wolfowitza_.

```{r}
resi <- modelMNK$residuals
runs.test(resi)
```

Ponieważ _p-value_ jest duże nie możemy odrzucić H0 dla poziomy istotności 0.01. To oznacza, że według testu serii liniowa postać modelu jest prawidłowa.

Następnie mysimy sprawdzić, które ze zmiennych powinny wchodzić w skład tego modelu. Do tego zastosujemy _metodę krokowo wsteczną_ i będziemy korzystać z testu t-studenta. Przed tym będziemy musieli sprawdzić normalność reszt. Sprawdzimy to testem _Shapiro-Wilka_.

```{r}
shapiro.test(resi)
```
Ponieważ p-value jest większe od 0.01 nie możemy odrzucić hipotezy zerowej, czyli możemy skorzystać z test _t-studenta_.
```{r}
summary(modelMNK)
```
Zmienną nieistotną dla tego modelu jest zmienna _Z6_. Ta zmienna zostanie usunięta, a następnie zostanie sprawdzone, czy nie ma jeszcze jakiejś zmiennej nieistotnej.

```{r}
modelMNK2 <- lm(train[,-6])
summary(modelMNK2)
resi2 <- modelMNK2$residuals
shapiro.test(resi2)
```
Reszta zmiennych w tym modelu jest istotna dla poziomu istotności 0.05. 

Następnie zostanie stworzona ramka danych _trainFrame_, w której będą się znajdować zmienne wraz z podzmiennymi stworzonymi w ramach przekształcenia zmiennej _Z7_.

```{r warning=FALSE}
testFrame <- test[,c(-6)]
trainFrame <- train[,c(-6)]
trainFrame <- trainFrame%>%mutate(const=rep(1,90))%>%spread(Z7,const,0)%>%select(-large)
```
## Zad 3
Dla wybranej postaci możemy wykonać pozostałe testy. W tej części sprawdzimy współliniowość zmiennych, korzystając ze statystyki _VIF_.

```{r}
vif(modelMNK2)
```
Ponieważ wartości statystki są mniejsze od 10, więc w tym przypadku nie możemy mówić o zjawisku współliniowości zmiennych. Następnie sprawdzimy koincydentność modelu.

Następnie zatosuje test _Chowa_ do sprawdzenia stabilności modelu:

```{r}
sctest(Z1~Z2+Z3+Z4+medium+small, type="Chow",data=trainFrame)
```
Ponieważ p_value jest większe od 0.05 to nie ma podstaw do odrzucenia hipotezy H0, czyli model ma stabilną postać.
Następnie zbadamy występowanie zjawiska autokorelacjii wykorzystujÄ…c test _Durbina-Watsona_.
```{r}
dwtest(modelMNK2)
```
Ponieważ p_value jest większe od 0.05, więc nie ma podstaw do odrzucenia H0, która mówi o braku zjawiska autokorealcji.

## Zad 4
Współczynnik determinacji R^2:
```{r}
summary(modelMNK2)$r.squared
```

Ponieważ współczynnik determinacji wynosi około 89%, model może posłużyć nam do predykcji.

## Zad 5
Wykonanie predykcji punktowe i przedziałowej na podstawie modelu z zadania 4.

```{r}
x_predict <- data.frame(-10.5,8,51.7,6,"large")
names(x_predict) <-c('Z2','Z3','Z4','Z5','Z7')
predict.lm(modelMNK2, x_predict, interval="confidence", level=0.95)
```
Pierwsza wartość jest predykcją punktową, która wynosi 22,31. Natomiast predykcja przedziałowa wynosi 11,88 i 31,08.

## Zad 6
Na tym etapie musi zostać wyznaczona prognoza _Ex Post_ dla całego podzbioru testowego oraz dla każdej obserwacji:

```{r}
predictions <- predict.lm(modelMNK2, testFrame)
predictions
ex_post <- testFrame$Z1 - predictions
ex_post
```

## Zad 7
Kolejnym korkiem jest wyliczenie błędu predykcji _Ex Post_ do wyliczenia średniego błędu predykcji _Ex Post_.

```{r}
mean(ex_post)
```

Stosowanie tego błędu jest niewskazane, kiedy mamy doczynienia ze statystyką błędu o ujemnym znaku, ponieważ zmniejsza on wartości o dodatnim znaku.

## Zad 8
Aby pozbyć się błędu z zadania 7 skorzystamy z wyliczenia średniej z wartości bezwzględnej błędu predykcji.

```{r}
mean(abs(ex_post))
```

## Zad 9 
Następnie zastosujemy średniokwadratowy błąd predykcji:

```{r}
MSE <- mean(ex_post^2)
RMSE <- sqrt(mean(ex_post^2))
MSE
RMSE
```

Statystyka _RMSE_ jest dużo bardziej podatna na duże wartośći niż statystyka z zadania 8.

## Zad 10

```{r}
mean(abs(ex_post/testFrame$Z1))
```
Błąd jest napradę duży, a jego wartość wynosi 140%, co oznacza, że model nie spełnia założeń o dokładności predykcji (założenie: granica 5%).
