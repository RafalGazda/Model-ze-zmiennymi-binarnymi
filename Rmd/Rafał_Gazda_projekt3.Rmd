---
title: "Cwiczenia 3"
author: "RafaÅ‚ Gazda"
date: "15 grudnia 2018"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r warning=FALSE, message=FALSE}
library(caTools)
library(lmtest)
library(randtests)
library(strucchange)
library(car)
library(tidyr)
library(dplyr)

```
## Zad 1

Po wgraniu danych, które zawieraj¹ 100 obserwacji zostan¹ one podzielone na dwie czêœæi _train_ oraz _test_. Za pomoc¹ czêœæi _train_ zbudujemy model ekonometryczny, a za pomoc¹ próbki _test_ zostanie on przetestowany.

```{r}
MyData <- read.csv('C:/Users/Gazi/Desktop/Projekt3/DaneZ3.csv', header=TRUE, sep=";", dec=',')
set.seed(284095)

sample = sample(1:100, 10, replace=FALSE)
train = MyData[-sample,] 
test = MyData[sample,]
```

## Zad 2
W projekcie zostanie dobrana odpowiednia postaæ modelu ekonometrycznego. Podczas budowy modelu trzeba zwórciæ uwagê na zmienn¹ _Z7_, która nie jest zmienn¹ numeryczn¹, dlatego te¿ zostanie ona zmieniona na zmienne zero-jedynkowe.

```{r}
modelMNK <- lm(train)
summary(modelMNK)
```
W tej czêœci projektu zostanie sprawdzone, czy postaæ liniowa jest optymalna. Pos³u¿ do tego testem _serii Walda-Wolfowitza_.

```{r}
resi <- modelMNK$residuals
runs.test(resi)
```

Poniewa¿ _p-value_ jest du¿e nie mo¿emy odrzuciæ H0 dla poziomy istotnoœci 0.01. To oznacza, ¿e wed³ug testu serii liniowa postaæ modelu jest prawid³owa.

Nastêpnie mysimy sprawdziæ, które ze zmiennych powinny wchodziæ w sk³ad tego modelu. Do tego zastosujemy _metodê krokowo wsteczn¹_ i bêdziemy korzystaæ z testu t-studenta. Przed tym bêdziemy musieli sprawdziæ normalnoœæ reszt. Sprawdzimy to testem _Shapiro-Wilka_.

```{r}
shapiro.test(resi)
```
Poniewa¿ p-value jest wiêksze od 0.01 nie mo¿emy odrzuciæ hipotezy zerowej, czyli mo¿emy skorzystaæ z test _t-studenta_.
```{r}
summary(modelMNK)
```
Zmienn¹ nieistotn¹ dla tego modelu jest zmienna _Z6_. Ta zmienna zostanie usuniêta, a nastêpnie zostanie sprawdzone, czy nie ma jeszcze jakiejœ zmiennej nieistotnej.

```{r}
modelMNK2 <- lm(train[,-6])
summary(modelMNK2)
resi2 <- modelMNK2$residuals
shapiro.test(resi2)
```
Reszta zmiennych w tym modelu jest istotna dla poziomu istotnoœci 0.05. 

Nastêpnie zostanie stworzona ramka danych _trainFrame_, w której bêd¹ siê znajdowaæ zmienne wraz z podzmiennymi stworzonymi w ramach przekszta³cenia zmiennej _Z7_.

```{r warning=FALSE}
testFrame <- test[,c(-6)]
trainFrame <- train[,c(-6)]
trainFrame <- trainFrame%>%mutate(const=rep(1,90))%>%spread(Z7,const,0)%>%select(-large)
```
## Zad 3
Dla wybranej postaci mo¿emy wykonaæ pozosta³e testy. W tej czêœci sprawdzimy wspó³liniowoœæ zmiennych, korzystaj¹c ze statystyki _VIF_.

```{r}
vif(modelMNK2)
```
Poniewa¿ wartoœci statystki s¹ mniejsze od 10, wiêc w tym przypadku nie mo¿emy mówiæ o zjawisku wspó³liniowoœci zmiennych. Nastêpnie sprawdzimy koincydentnoœæ modelu.

Nastêpnie zatosuje test _Chowa_ do sprawdzenia stabilnoœci modelu:

```{r}
sctest(Z1~Z2+Z3+Z4+medium+small, type="Chow",data=trainFrame)
```
Poniewa¿ p_value jest wiêksze od 0.05 to nie ma podstaw do odrzucenia hipotezy H0, czyli model ma stabiln¹ postaæ.
Nastêpnie zbadamy wystêpowanie zjawiska autokorelacjii wykorzystujÄ…c test _Durbina-Watsona_.
```{r}
dwtest(modelMNK2)
```
Poniewa¿ p_value jest wiêksze od 0.05, wiêc nie ma podstaw do odrzucenia H0, która mówi o braku zjawiska autokorealcji.

## Zad 4
Wspó³czynnik determinacji R^2:
```{r}
summary(modelMNK2)$r.squared
```

Poniewa¿ wspó³czynnik determinacji wynosi oko³o 89%, model mo¿e pos³u¿yæ nam do predykcji.

## Zad 5
Wykonanie predykcji punktowe i przedzia³owej na podstawie modelu z zadania 4.

```{r}
x_predict <- data.frame(-10.5,8,51.7,6,"large")
names(x_predict) <-c('Z2','Z3','Z4','Z5','Z7')
predict.lm(modelMNK2, x_predict, interval="confidence", level=0.95)
```
Pierwsza wartoœæ jest predykcj¹ punktow¹, która wynosi 22,31. Natomiast predykcja przedzia³owa wynosi 11,88 i 31,08.

## Zad 6
Na tym etapie musi zostaæ wyznaczona prognoza _Ex Post_ dla ca³ego podzbioru testowego oraz dla ka¿dej obserwacji:

```{r}
predictions <- predict.lm(modelMNK2, testFrame)
predictions
ex_post <- testFrame$Z1 - predictions
ex_post
```

## Zad 7
Kolejnym korkiem jest wyliczenie b³êdu predykcji _Ex Post_ do wyliczenia œredniego b³êdu predykcji _Ex Post_.

```{r}
mean(ex_post)
```

Stosowanie tego b³êdu jest niewskazane, kiedy mamy doczynienia ze statystyk¹ b³êdu o ujemnym znaku, poniewa¿ zmniejsza on wartoœci o dodatnim znaku.

## Zad 8
Aby pozbyæ siê b³êdu z zadania 7 skorzystamy z wyliczenia œredniej z wartoœci bezwzglêdnej b³êdu predykcji.

```{r}
mean(abs(ex_post))
```

## Zad 9 
Nastêpnie zastosujemy œredniokwadratowy b³¹d predykcji:

```{r}
MSE <- mean(ex_post^2)
RMSE <- sqrt(mean(ex_post^2))
MSE
RMSE
```

Statystyka _RMSE_ jest du¿o bardziej podatna na du¿e wartoœæi ni¿ statystyka z zadania 8.

## Zad 10

```{r}
mean(abs(ex_post/testFrame$Z1))
```
B³¹d jest napradê du¿y, a jego wartoœæ wynosi 140%, co oznacza, ¿e model nie spe³nia za³o¿eñ o dok³adnoœci predykcji (za³o¿enie: granica 5%).
